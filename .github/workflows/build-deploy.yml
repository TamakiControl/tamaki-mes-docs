name: Deploy Docusaurus to GitHub Pages

on:
  push:
    branches:
      - master  # Deploy when changes are pushed to the main branch. Adjust if needed.

jobs:
  build-and-deploy:
    runs-on: ubuntu-latest

    env:
      APPLICATION_ID: ${{ secrets.APPLICATION_ID }}
      URL: ${{ secrets.URL }}
      BASE_URL: ${{ secrets.BASE_URL }}
      GH_DOCS_URL: ${{ secrets.GH_DOCS_URL }}
      GH_CODE_URL: ${{ secrets.GH_CODE_URL }}
      STACK_OVERFLOW_URL: ${{ secrets.STACK_OVERFLOW_URL }}
      TYPESENSE_API_KEY: ${{ secrets.TYPESENSE_API_KEY }}
      TYPESENSE_HOST: ${{ secrets.TYPESENSE_HOST }}
      TYPESENSE_PORT: ${{ secrets.TYPESENSE_PORT }}
      TYPESENSE_PROTOCOL: ${{ secrets.TYPESENSE_PROTOCOL }}
      TYPESENSE_COLLECTION_NAME: ${{ secrets.TYPESENSE_COLLECTION_NAME }}

    steps:
      - name: Checkout repository
        uses: actions/checkout@v3

      - name: Set up Node.js
        uses: actions/setup-node@v3
        with:
          node-version: '22'  # Use a Node.js version compatible with Docusaurus

      - name: Install dependencies
        run: |
          npm install

      - name: Build Docusaurus
        run: |
          npm run build

      - name: Serve site for scraper
        run: |
          # Use Docusaurus's own server which correctly handles the site's baseUrl
          # Run it in the background on port 8080
          npm run serve -- --port 8080 &
          # Wait for server to start before proceeding
          sleep 5
          sudo apt-get update && sudo apt-get install -y jq

      - name: Create .env file
        run: |
          echo "TYPESENSE_API_KEY=${{ secrets.TYPESENSE_API_KEY }}" > .env
          echo "TYPESENSE_HOST=${{ secrets.TYPESENSE_HOST }}" >> .env
          echo "TYPESENSE_PORT=${{ secrets.TYPESENSE_PORT }}" >> .env
          echo "TYPESENSE_PROTOCOL=${{ secrets.TYPESENSE_PROTOCOL }}" >> .env
          echo "TYPESENSE_COLLECTION_NAME=${{ secrets.TYPESENSE_COLLECTION_NAME }}" >> .env
          
      - name: Clean previous alias to prevent scraper bug
        run: |
          curl -i -X DELETE \
            -H "X-TYPESENSE-API-KEY: ${{ secrets.TYPESENSE_API_KEY }}" \
            "https://${{ secrets.TYPESENSE_HOST }}:${{ secrets.TYPESENSE_PORT }}/aliases/${{ secrets.TYPESENSE_COLLECTION_NAME }}" || true

      - name: Create scraper config file
        run: |
          # The docusaurus serve command respects the baseUrl, so we must include it in the scraper's start_urls
          CONFIG_CONTENT=$(cat typesense-config.json | jq '.start_urls = ["http://host.docker.internal:8080${{ secrets.BASE_URL }}"] | .sitemap_urls = ["http://host.docker.internal:8080${{ secrets.BASE_URL }}sitemap.xml"] | .allowed_domains = ["host.docker.internal"]')
          echo "$CONFIG_CONTENT" > gh-action-scraper-config.json

      - name: Run docsearch-scraper
        run: |
          docker run -i --env-file .env \
            --add-host=host.docker.internal:host-gateway \
            -e "CONFIG=/config.json" \
            -v "$(pwd)/gh-action-scraper-config.json:/config.json:ro" \
            typesense/docsearch-scraper:0.11.0

      - name: Deploy to GitHub Pages
        uses: peaceiris/actions-gh-pages@v3
        with:
          github_token: ${{ secrets.GITHUB_TOKEN }}
          publish_dir: ./build  # Path to the built files
          keep_files: true  # Keeps existing files in the gh-pages branch
